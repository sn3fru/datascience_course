{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erro tipo I e erro tipo II\n",
    "\n",
    "Em testes de hipóteses estatísticas, um erro tipo I é a rejeição de uma hipótese nula verdadeira (também conhecida como conclusão ou conclusão \"falso positivo\"), enquanto um erro tipo II é a falha em rejeitar uma hipótese nula falsa (também conhecida como achado ou conclusão \"falso-negativo\". Mais simplesmente afirmado, um erro tipo I é falsamente inferir a existência ou realidade de algo que de fato não é real ou não existe de fato (ou seja, conforme a crença comum com informações falsas), enquanto um erro tipo II é falsamente inferir a ausência ou inexistência de algo que é real ou existe (isto é, uma conclusão que vai contra a crença comum com informações falsas). Grande parte da teoria estatística gira em torno da minimização de um ou de ambos os erros, embora a eliminação completa de ambos seja tratada como uma impossibilidade estatística.\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"img/tipos_erro.png\" width=\"550\" />\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como medir o erro no problema de classificação?\n",
    "\n",
    "O erro tipo I (falso positivo) e o erro tipo II (falso negativo) nos ajudam a identificar a precisão do nosso modelo, que pode ser encontrado com a ajuda d Matriz de Confusão. Se somarmos o valor do Tipo I e Erro Tipo II, poderemos ter um Erro Total = Falso Negativo + Falso Positivo.\n",
    "\n",
    "A precisão será maior se o erro for menor e vice-versa. Melhor precisão, melhor desempenho e exatamente o que queremos.\n",
    "\n",
    "Vamos falar sobre o resultado que obtivemos na seção de código python, para o exemplo abaixo onde temos que comparar a situação real com os valoress preditos para mulheres grávidas, e analisar os erros obtidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_real = [1,0,0,0,0,0,1,1,1,0]\n",
    "y_hat  = [1,1,1,0,0,0,1,1,0,0]\n",
    "\n",
    "print(confusion_matrix(y_real,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falso Positivo = 2, significa que 2 mulheres não estão grávidas na realidade, mas a previsão do modelo diz que elas estão grávidas.\n",
    "\n",
    "Falso Negativo = 1, o que significa que 1 senhora está grávida, mas, de acordo com a previsão, ela não está grávida. Portanto, este caso é mais perigoso porque uma mulher está grávida e a previsão do modelo diz que ela não é. Então, o Erro Tipo II aqui é mais perigoso do que o Erro Tipo I.\n",
    "\n",
    "Podemos concluir que, de 10 previsões, o nosso modelo fez 3 previsões erradas (1 Falso Negativo + 2 Falso-Positivo) e 7 previsões corretas (4 Verdadeiro Positivo +3 Verdadeiro Negativo). Então a precisão do modelo podemos dizer 70% e erro 30%.\n",
    "\n",
    "<br>\n",
    "<img src=\"img/matriz_confusao.png\" width=\"550\" />\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP=confusion_matrix(y_real,y_hat)[0][1] #Erro tipo I\n",
    "FN=confusion_matrix(y_real,y_hat)[1][0] #Erro tipo II\n",
    "\n",
    "print('Falso Positivo (erro tipo I):', FP)\n",
    "print('Falso Negativo (erro tipo II):', FN)\n",
    "\n",
    "accuracy = 100-((FP+FN)*100)/len(y_hat)\n",
    "print('Acurácia:',accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
