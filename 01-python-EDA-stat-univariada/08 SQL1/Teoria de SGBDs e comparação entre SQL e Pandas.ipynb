{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL\n",
    "\n",
    "<br>\n",
    "<img src=\"img/sql_example.png\" width=\"700\" />\n",
    "<br>\n",
    "\n",
    "Structured Query Language, ou Linguagem de Consulta Estruturada ou SQL, é a linguagem de pesquisa declarativa padrão para banco de dados relacional (base de dados relacional). Muitas das características originais do SQL foram inspiradas na álgebra relacional.\n",
    "\n",
    "O SQL foi desenvolvido originalmente no início dos anos 70 nos laboratórios da IBM em San Jose, dentro do projeto System R, que tinha por objetivo demonstrar a viabilidade da implementação do modelo relacional proposto por E. F. Codd. O nome original da linguagem era SEQUEL, acrônimo para \"Structured English Query Language\" (Linguagem de Consulta Estruturada, em Inglês), vindo daí o facto de, até hoje, a sigla, em inglês, ser comumente pronunciada \"síquel\" ao invés de \"és-kiú-él\", letra a letra. No entanto, em português, a pronúncia mais corrente é letra a letra: \"ésse-quê-éle\".\n",
    "\n",
    "A linguagem é um grande padrão de banco de dados. Isto decorre da sua simplicidade e facilidade de uso. Ela se diferencia de outras linguagens de consulta a banco de dados no sentido em que uma consulta SQL especifica a forma do resultado e não o caminho para chegar a ele. Ela é uma linguagem declarativa em oposição a outras linguagens procedurais. Isto reduz o ciclo de aprendizado daqueles que se iniciam na linguagem.\n",
    "\n",
    "Embora o SQL tenha sido originalmente criado pela IBM, rapidamente surgiram vários \"dialectos\" desenvolvidos por outros produtores. Essa expansão levou à necessidade de ser criado e adaptado um padrão para a linguagem. Esta tarefa foi realizada pela American National Standards Institute (ANSI) em 1986 e ISO em 1987.\n",
    "\n",
    "O SQL foi revisto em 1992 e a esta versão foi dado o nome de SQL-92. Foi revisto novamente em 1999 e 2003 para se tornar SQL:1999 (SQL3) e SQL:2003, respectivamente. O SQL:1999 usa expressões regulares de emparelhamento, queries recursivas e gatilhos (triggers). Também foi feita uma adição controversa de tipos não-escalados e algumas características de orientação a objeto. O SQL:2003 introduz características relacionadas ao XML, sequências padronizadas e colunas com valores de auto-generalização (inclusive colunas-identidade).\n",
    "\n",
    "Tal como dito anteriormente, embora padronizado pela ANSI e ISO, possui muitas variações e extensões produzidos pelos diferentes fabricantes de sistemas gerenciadores de bases de dados. Tipicamente a linguagem pode ser migrada de plataforma para plataforma sem mudanças estruturais principais.\n",
    "\n",
    "Outra aproximação é permitir para código de idioma procedural ser embutido e interagir com o banco de dados. Por exemplo, o Oracle e outros incluem Java na base de dados, enquanto o PostgreSQL permite que funções sejam escritas em Perl, Tcl, ou C, entre outras linguagens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoSQL\n",
    "\n",
    "<br>\n",
    "<img src=\"img/nosql.png\" width=\"800\" />\n",
    "<br>\n",
    "\n",
    "NoSQL (originalmente se referindo a \"no SQL\": \"não SQL\" ou \"não relacional\", posteriormente estendido para Not Only SQL - Não Somente SQL) é um termo genérico que representa os bancos de dados não relacionais. Uma classe definida de banco de dados que fornecem um mecanismo para armazenamento e recuperação de dados que são modelados de formas diferentes das relações tabulares usadas nos bancos de dados relacionais.\n",
    "\n",
    "Tais bancos de dados existem desde o final da década de 1960, mas não obtiveram o apelido de \"NoSQL\" até atingirem sua onda de popularidade no início do século vinte e um, desencadeada pelas necessidades das empresas de Web 2.0 como Facebook, Google e Amazon.com. Bancos de dados NoSQL são cada vez mais usados em big data e aplicações web de tempo real. Sistemas NoSQL, às vezes, também são chamados de \"Not only SQL\" (\"Não apenas SQL\") para enfatizar que eles podem suportar linguagens de consulta semelhantes à SQL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Vs. NoSQL\n",
    "\n",
    "<br>\n",
    "<img src=\"img/sql_graph.png\" width=\"400\" />\n",
    "<br>\n",
    "\n",
    "## Definição de NoSQL:\n",
    "\n",
    "Bases de dados de próxima geração, abordando principalmente alguns dos pontos: sendo não-relacional, distribuído, de código aberto e horizontalmente escalável.\n",
    "\n",
    "A intenção original tem sido bancos de dados modernos em escala web. O movimento começou no início de 2009 e está crescendo rapidamente. Muitas vezes, mais características se aplicam, tais como: livre de esquema, fácil suporte a replicação, API simples, eventualmente consistente / BASE (não ACID), uma enorme quantidade de dados e muito mais. Portanto, o termo enganoso \"nosql\" (a comunidade agora traduz principalmente com **\"não apenas sql\"**) deve ser visto como um alias para algo como a definição acima.\n",
    "\n",
    "<br>\n",
    "<img src=\"img/tools.png\" width=\"400\" />\n",
    "<br>\n",
    "\n",
    "Quase todos os aplicativos precisam de dados para serem armazenados. Esses dados precisam invariavelmente ser buscados, atualizados e pesquisados. Isso torna necessário que os aplicativos usem algum tipo de armazenamento de dados. Por muito tempo, soluções baseadas em RDBMS como SQL dominaram o polo. O SQL suporta operações básicas como CRUD nos dados, juntamente com algumas operações complexas, como agregação. No entanto, o NoSQL agora está desafiando seriamente as soluções de RDBMS para executar operações semelhantes.\n",
    "\n",
    "### Comparação de recursos\n",
    "\n",
    "Vejamos alguns dos recursos que cada uma dessas soluções fornece nos dados subjacentes.\n",
    "\n",
    "### Esquema\n",
    "\n",
    "O SQL funciona em esquemas com rigidez de tipos, em que cada relação (tabela) tem colunas predefinidas. O SQL foi otimizado para executar consultas complexas, como agregação. O NoSQL, por outro lado, não está em conformidade com nenhum esquema fortemente vinculado. Então, em teoria, todo registro NoSQL pode ter esquemas diferentes. Isso facilita o armazenamento de dados não estruturados. A maioria das soluções NoSQL fornece algum tipo de solução, como o Map Reduce para fornecer suporte a recursos complexos.\n",
    "\n",
    "Como o NoSQL não possui nenhum esquema restrito, é possível que os dados sejam armazenados erroneamente em uma chave errada e, ao buscar dados, o resultado pode não ser o esperado. No entanto, no SQL, alterar o esquema pode ser uma operação complicada, pois bloqueia a tabela inteira até que a operação de alteração seja concluída, o que poderia bloquear as transações nessa tabela.\n",
    "\n",
    "### Consultas\n",
    "\n",
    "Qualquer banco de dados deve fornecer recursos para consultar os dados subjacentes.\n",
    "\n",
    "SQL é uma linguagem de consulta padrão, que fornece uma maneira padrão de executar consultas nos dados. Todo provedor de banco de dados fornece mais otimização no SQL. As consultas podem ser escritas para realizar cálculos complexos nos dados presentes no banco de dados.\n",
    "\n",
    "NoSQL, por outro lado, as consultas não são tão exaustivas quanto o SQL. Embora tenha sido adicionado mais suporte para consultar dados do NoSQL, ainda há muito o que fazer. Cada solução NoSQL varia de um para o outro de uma forma que os dados podem ser consultados, portanto, não são consistentes. Além disso, para fornecer computação complexa em dados, o NoSQL depende de algumas tecnologias subjacentes, como o Map Reduce.\n",
    "\n",
    "### Transações\n",
    "\n",
    "As transações formam um recurso muito importante para qualquer banco de dados.\n",
    "\n",
    "O SQL fornece um forte suporte para transações atômicas. Um conjunto de consultas SQL pode ser agrupado em uma transação e a transação pode ser confirmada após todas as consultas terem sido executadas. Se qualquer uma das consultas gerar algum erro, toda a transação poderá ser revertida. Isso fornece suporte forte para transações atômicas.\n",
    "\n",
    "O suporte do NoSQL para transação ainda está em um estágio muito inicial. Muitas das soluções NoSQL ainda não fornecem suporte para transações.\n",
    "\n",
    "### Consistência\n",
    "\n",
    "O SQL fornece um forte suporte para consistência. Os dados são completamente confirmados em um servidor SQL. Com a arquitetura mestre-escravo, os dados podem ser replicados para múltiplos escravos do mestre de forma assíncrona. No entanto, se o mestre falhar antes da replicação, existe o risco de perder dados.\n",
    "\n",
    "O NoSQL segue a abordagem de consistência para fornecer consistência. Isso significa que os dados serão eventualmente replicados para todos os nós e os dados serão consistentes em todos os nós. Isso também significa que não há garantia de que os dados buscados estejam atualizados.\n",
    "\n",
    "### Escalabilidade\n",
    "\n",
    "O SQL fornece escalabilidade vertical. Isso significa que para tornar o SQL mais escalável, a capacidade de hardware do servidor precisa ser aumentada. Isso torna os servidores de banco de dados caros e difíceis de manter.\n",
    "\n",
    "NoSQL escala horizontalmente. Se o volume dos dados aumentar, basta adicionar outro servidor para lidar com o aumento do volume. A maioria dos servidores NOSQL são servidores comuns e são muito mais fáceis de manter. Isso também torna os servidores NoSQL capazes de lidar com uma quantidade muito grande de dados.\n",
    "\n",
    "### O que usar\n",
    "\n",
    "Tendo visto os recursos que cada uma dessas soluções fornece, precisamos examinar qual é a solução mais apropriada para armazenar dados em um aplicativo. Aplicação onde os dados podem ser manipulados na memória, o SQL faz uma escolha melhor. Peças onde os dados não estão claramente definidos e os dados são muito grandes, então o NoSQL faz uma escolha melhor. As junções no SQL são lentas e caras. Como os dados podem ser armazenados sem qualquer esquema estrito, podemos armazenar qualquer tipo de dados no NoSQL, o que pode nos ajudar a obter dados evitando junções. Além disso, onde a escalabilidade é de importância primária, os bancos de dados NoSQL oferecem uma opção muito boa.\n",
    "\n",
    "Ambas as soluções podem coexistir em um aplicativo. Podemos aproveitar os benefícios de cada uma dessas soluções em diferentes partes do aplicativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big-Data\n",
    "\n",
    "<br>\n",
    "<img src=\"img/big_data.png\" width=\"900\" />\n",
    "<br>\n",
    "\n",
    "Em tecnologia da informação, o termo big data refere-se a um grande conjunto de dados gerados e armazenados com os quais os aplicativos de processamento de dados tradicionais ainda não conseguem lidar em um tempo tolerável. Seu surgimento está relacionado com o aumento exponencial da quantidade de dados gerados a cada minuto no mundo. O big data representou uma nova era na sociedade moderna, em que os dados se tornaram cada vez mais valiosos, mudando a forma como a economia e a ciência observam os processos, extraem e geram valor desse caos de dados. \n",
    "\n",
    "Ao longo das últimas décadas, a quantidade de dados gerados tem crescido de forma exponencial. O surgimento da internet fez sairmos da era do terabyte para o petabyte, e a internet das coisas aumentou de forma abrupta a quantidade de dados gerados. Em 2015, entramos na era do zetabytes, e atualmente geramos mais de 2,5 quintilhões de bytes diariamente. A esta quantidade enorme de dados foi dado o nome de big data. Este termo surgiu em 1997 e seu uso foi utilizado para nomear essa quantidade cada vez mais crescente e não estruturadas de dados sendo gerados a cada segundo. Atualmente o big data é essencial nas relações econômicas e sociais e representou uma evolução nos sistemas de negócio e na ciência. As ferramentas de big data são de grande importância na definição de estratégias de marketing, aumentar a produtividade, reduzir custos e tomar decisões mais inteligentes. A essência do conceito está em gerar valor para negócios. No que tange a ciência, o surgimento do big data representou a criação de um novo paradigma (4° paradigma) sendo concebido um novo método de avançar as fronteiras do conhecimento, por meio de novas tecnologias para coletar, manipular, analisar e exibir dados, construindo valor agregado com as análises geradas.\n",
    "\n",
    "Quanto mais dados são gerados, maior é o esforço para extrair informações, e os centros de dados tiveram que aprender a lidar com o crescimento exponencial de dados gerados e tiveram que desenvolver ferramentas que fossem para além de bancos de dados relacionais e sistemas paralelos de bancos de dados. Sendo assim, a velocidade para obter a informação faz parte do sucesso que o big data pode proporcionar em sua empresa. O conceito de big data foi definido inicialmente por 3'V mas a literatura mostrou que seu conceito pode ser expandido para 5'V, representados pelos seguintes conceitos:\n",
    "\n",
    "- Volume: relacionado a grande quantidade de dados gerados;\n",
    "- Variedade: as fontes de dados são muito variadas, o que aumenta a complexidade das análises;\n",
    "- Velocidade: Devido ao grande volume e variedade de dados, todo o processamento deve ser ágil para gerar as informações necessárias;\n",
    "- Veracidade: A veracidade está ligada diretamente ao quanto uma informação é verdadeira.\n",
    "- Valor: Este conceito está relacionado com o valor obtido desses dados, ou seja, com a “informação útil”.\n",
    "\n",
    "<br>\n",
    "<img src=\"img/social_network.png\" width=\"700\" />\n",
    "<br>\n",
    "\n",
    "Existem tipos básicos de dados que são estudados pelos especialistas em big data, os conceitos mais utilizados geralmente envolvem:\n",
    "\n",
    "- Social Data: Dados coletados de redes sociais ou ambientes de interação entre usuários, geralmente demográficos e comportamentais, ou seja, ditam um padrão de um determinado grupo com as mesmas característica. O Social Data é muito utilizado na análise de campanhas de marketing, de maneira a oferecer um serviço ou produto mais personalizado de acordo com diferentes segmentos.\n",
    "- Enterprise Data: Na tradução literal Dados Empresariais, coletados pelo RH de empresas, setores de vendas, finanças, logística e produção, esses dados são atributos sobre funcionários e setores diferentes dentro de um ambiente empresarial, podem ser utilizados para otimizar processos e identificar falhas ou fraudes dentro de uma determinada seção, esse tipo de dado é um marco de investimento estratégico de grandes empresas, que visam minimizar gastos e otimizar lucros.\n",
    "- Personal Data: Dados pessoais, facilmente relacionados ao conceito da Internet das coisas, são dados obtidos através de aparelhos de uso pessoal ou coletivo, tais como smartphones, geladeiras, televisões, carros, etc. Esse tipo de dado mostra as preferências pessoais de um determinado indivíduo através do estudo de padrões, por meio do uso do Personal Data é possível desenvolver metodologias personalizadas de interação com o cliente, de maneira a tornar a relação com o produto menos mecanizada e robotizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praticando SQL\n",
    "\n",
    "<br>\n",
    "<img src=\"img/sql_zoo.png\" width=\"200\" />\n",
    "<br>\n",
    "\n",
    "Para prática de SQL utilizar o aplicativo SQL Zoo [clicando aqui](https://sqlzoo.net/wiki/SELECT_basics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anatomia de uma SQL query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma consulta SQL consiste em algumas palavras-chave importantes. Entre essas palavras-chave, você adiciona os detalhes de quais dados, exatamente, deseja ver. Aqui está uma consulta esquelética sem os detalhes:\n",
    "\n",
    "\n",
    "    SELECT… FROM… WHERE…\n",
    "\n",
    "    GROUP BY… HAVING…\n",
    "\n",
    "    ORDER BY…\n",
    "\n",
    "    LIMIT… OFFSET…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acessando o banco de dados e lendo todos os arquivos utilizados no curso\n",
    "\n",
    "Faremos a comparação do que foi acessado com os arquivos que temos em csv para verificar se todos os arquivos estão completos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "!pip install -U -q pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectando em um banco local postgresql com psycopg2 ou mysql com pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\marcos.silva\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.7.6.1)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\marcos.silva\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.2.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2\n",
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "#import psycopg2\n",
    "import pymysql\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import io\n",
    "\n",
    "host = 'dh-ds-t1-2019.cpvwsnqnnd2w.us-east-1.rds.amazonaws.com' #substituir pelo host que você for utilizar\n",
    "port = 5432 \n",
    "dbname = 'DHds2019' #substituir pelo nome do banco que você criar\n",
    "username = 'digitalhouse' #substituir pelo nome de usuário do banco que você for usar\n",
    "pwd = 'alunosDH19' #substituir pela senha do usuário que você estiver usando\n",
    "\n",
    "#conn = psycopg2.connect(f\"host='{host}' port={port}  dbname='{dbname}' user={username} password={pwd}\")\n",
    "p_engine = create_engine('postgresql://'+p_username+':'+p_pwd+'@'+p_host+':'+str(p_port)+'/'+p_dbname)\n",
    "m_engine = create_engine('mysql+pymysql://'+m_username+':'+m_pwd+'@'+m_host+':'+str(m_port)+'/'+m_dbname, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT, WHERE, DISTINCT, LIMIT\n",
    "\n",
    "\n",
    "Aqui estão algumas instruções SELECT. Nós truncamos os resultados com LIMIT e os filtramos com WHERE. Usamos DISTINCT para remover resultados duplicados.    \n",
    "\n",
    "\n",
    "|                      SQL                     |                 Pandas                |\n",
    "|:--------------------------------------------:|:-------------------------------------:|\n",
    "| select * from airports                       | airports                              |\n",
    "| select * from airports limit 3               | airports.head(3)                      |\n",
    "| select id from airports where ident = 'KLAX' | airports[airports.ident == 'KLAX'].id |\n",
    "| select distinct type from airport            | airports.type.unique()                |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT with multiple conditions\n",
    "\n",
    "Nós nos juntamos a múltiplas condições com um &. Se quisermos apenas um subconjunto de colunas da tabela, esse subconjunto será aplicado em outro par de colchetes.\n",
    "\n",
    "|                                                  SQL                                                 |                                                       Pandas                                                       |\n",
    "|:----------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------:|\n",
    "| select * from airports where iso_region = 'US-CA' and type = 'seaplane_base'                         | airports[(airports.iso_region == 'US-CA') & (airports.type == 'seaplane_base')]                                    |\n",
    "| select ident, name, municipality from airports where iso_region = 'US-CA' and type = 'large_airport' | airports[(airports.iso_region == 'US-CA') & (airports.type == 'large_airport')][['ident', 'name',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORDER BY\n",
    "\n",
    "Por padrão, os Pandas ordenarão as coisas em ordem crescente. Para inverter isso, forneça ascendente = Falso.\n",
    "\n",
    "|                                     SQL                                    |                                          Pandas                                         |\n",
    "|:--------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------:|\n",
    "| select * from airport_freq where airport_ident = 'KLAX' order by type      | airport_freq[airport_freq.airport_ident == 'KLAX'].sort_values('type')                  |\n",
    "| select * from airport_freq where airport_ident = 'KLAX' order by type desc | airport_freq[airport_freq.airport_ident == 'KLAX'].sort_values('type', ascending=False) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN… NOT IN\n",
    "\n",
    "Sabemos como filtrar um valor, mas e quanto a uma lista de valores - condição IN? Nos pandas, o operador .isin () funciona da mesma maneira. Para negar qualquer condição, use ~.\n",
    "\n",
    "\n",
    "|                                  SQL                                 |                           Pandas                           |\n",
    "|:--------------------------------------------------------------------:|:----------------------------------------------------------:|\n",
    "| select * from airports where type in ('heliport', 'balloonport')     | airports[airports.type.isin(['heliport', 'balloonport'])]  |\n",
    "| select * from airports where type not in ('heliport', 'balloonport') | airports[~airports.type.isin(['heliport', 'balloonport'])] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUP BY, COUNT, ORDER BY\n",
    "\n",
    "O agrupamento é simples: use o operador .groupby (). Há uma diferença sutil entre a semântica de um COUNT no SQL e o Pandas. No Pandas, .count () retornará o número de valores não nulos / NaN. Para obter o mesmo resultado que o SQL COUNT, use .size ().\n",
    "\n",
    "\n",
    "|                                                           SQL                                                           |                                                                     Pandas                                                                    |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| select iso_country, type, count(&ast;) from airports group by iso_country, type order by iso_country, type              | airports.groupby(['iso_country', 'type']).size()                                                                                              |\n",
    "| select iso_country, type, count(&ast;) from airports group by iso_country, type order by iso_country, count(&ast;) desc | airports.groupby(['iso_country', 'type']).size().to_frame('size').reset_index().sort_values(['iso_country', 'size'], ascending=[True, False]) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Abaixo, agrupamos em mais de um campo. Os pandas classificarão as coisas na mesma lista de campos por padrão, portanto, não há necessidade de um .sort_values ​​() no primeiro exemplo. Se quisermos usar campos diferentes para ordenação, ou DESC ao invés de ASC, como no segundo exemplo, temos que ser explícitos:\n",
    "\n",
    "\n",
    "|                                                           SQL                                                           |                                                                     Pandas                                                                    |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| select iso_country, type, count(&ast;) from airports group by iso_country, type order by iso_country, type              | airports.groupby(['iso_country', 'type']).size()                                                                                              |\n",
    "| select iso_country, type, count(&ast;) from airports group by iso_country, type order by iso_country, count(&ast;) desc | airports.groupby(['iso_country', 'type']).size().to_frame('size').reset_index().sort_values(['iso_country', 'size'], ascending=[True, False]) |\n",
    "\n",
    "\n",
    "O que é esse truque com .to_frame () e .reset_index ()? Como queremos classificar pelo nosso campo calculado (tamanho), esse campo precisa se tornar parte do DataFrame. Após o agrupamento no Pandas, retornamos um tipo diferente, chamado GroupByObject. Então, precisamos convertê-lo de volta para um DataFrame. Com .reset_index (), reiniciamos a numeração de linhas para o nosso quadro de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAVING\n",
    "\n",
    "\n",
    "No SQL, você também pode filtrar dados agrupados usando uma condição HAVING. No Pandas, você pode usar .filter () e fornecer uma função Python (ou um lambda) que retornará True se o grupo deve ser incluído no resultado.\n",
    "\n",
    "\n",
    "|                                                                     SQL                                                                     |                                                                   Pandas                                                                   |\n",
    "|:-------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| select type, count(&ast;) from airports where iso_country = 'US' group by type having count(&ast;) > 1000 order by count(&ast;) desc | airports[airports.iso_country == 'US'].groupby('type').filter(lambda g: len(g) > 1000).groupby('type').size().sort_values(ascending=False) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top n Records\n",
    "\n",
    "Digamos que fizemos uma consulta preliminar e agora temos um dataframe chamado by_country, que contém o número de aeroportos por país:\n",
    "\n",
    "``by_country.head(3)``\n",
    "\n",
    "No próximo exemplo, pedimos coisas por airport_count e selecionamos apenas os 10 principais países com a maior contagem. O segundo exemplo é o caso mais complicado, no qual queremos “os próximos 10 depois do top 10”:\n",
    "\n",
    "\n",
    "|                                    SQL                                   |                           Pandas                          |\n",
    "|:------------------------------------------------------------------------:|:---------------------------------------------------------:|\n",
    "| select iso_country from by_country order by size desc limit 10           | by_country.nlargest(10, columns='airport_count')          |\n",
    "| select iso_country from by_country order by size desc limit 10 offset 10 | by_country.nlargest(20, columns='airport_count').tail(10) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate functions (MIN, MAX, MEAN)\n",
    "\n",
    "|                                           SQL                                          |                            Pandas                            |\n",
    "|:--------------------------------------------------------------------------------------:|:------------------------------------------------------------:|\n",
    "| select max(length_ft), min(length_ft), mean(length_ft), median(length_ft) from runways | runways.agg({'length_ft': ['min', 'max', 'mean', 'median']}) |\n",
    "\n",
    "\n",
    "\n",
    "função transposto para facilitar a viz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOIN\n",
    "\n",
    "Use .merge () para unir os dataframes do Pandas. Você precisa fornecer quais colunas deseja unir (left_on e right_on) e unir type: inner (default), left (corresponde a LEFT OUTER no SQL), right (RIGHT OUTER) ou outer (FULL OUTER).\n",
    "\n",
    "|                                                                               SQL                                                                              |                                                                                    Pandas                                                                                    |\n",
    "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| select airport_ident, type, description, frequency_mhz from airport_freq join airports on airport_freq.airport_ref = airports.id where airports.ident = 'KLAX' | airport_freq.merge(airports[airports.ident == 'KLAX'][['id']], left_on='airport_ref', right_on='id', how='inner')[['airport_ident', 'type', 'description', 'frequency_mhz']] |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNION and UNION ALL\n",
    "\n",
    "|                                                                 SQL                                                                 |                                                                  Pandas                                                                 |\n",
    "|:-----------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| select name, municipality from airports where ident = 'KLAX' union all select name, municipality from airports where ident = 'KLGB' | pd.concat([airports[airports.ident == 'KLAX'][['name', 'municipality']], airports[airports.ident == 'KLGB'][['name', 'municipality']]]) |\n",
    "\n",
    "\n",
    "Para desduplicar as coisas (equivalente a UNION), você também teria que adicionar .drop_duplicates ().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSERT\n",
    "\n",
    "|                         SQL                        |                                    Pandas                                   |\n",
    "|:--------------------------------------------------:|:---------------------------------------------------------------------------:|\n",
    "| create table heroes (id integer, name text);       | df1 = pd.DataFrame({'id': [1, 2], 'name': ['Harry Potter', 'Ron Weasley']}) |\n",
    "| insert into heroes values (1, 'Harry Potter');     | df2 = pd.DataFrame({'id': [3], 'name': ['Hermione Granger']})               |\n",
    "| insert into heroes values (2, 'Ron Weasley');      |                                                                             |\n",
    "| insert into heroes values (3, 'Hermione Granger'); | pd.concat([df1, df2]).reset_index(drop=True)                                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE\n",
    "|                                             SQL                                             |                                             Pandas                                             |\n",
    "|:-------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------:|\n",
    "| update airports set home_link = 'http://www.lawa.org/welcomelax.aspx' where ident == 'KLAX' | airports.loc[airports['ident'] == 'KLAX', 'home_link'] = 'http://www.lawa.org/welcomelax.aspx' |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE\n",
    "\n",
    "|                    SQL                   |                         Pandas                         |\n",
    "|:----------------------------------------:|:------------------------------------------------------:|\n",
    "| delete from lax_freq where type = 'MISC' | lax_freq = lax_freq[lax_freq.type != 'MISC']           |\n",
    "|                                          | lax_freq.drop(lax_freq[lax_freq.type == 'MISC'].index) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORTAÇÕES\n",
    "\n",
    "    df.to_csv(...)  # csv file\n",
    "    df.to_hdf(...)  # HDF5 file\n",
    "    df.to_pickle(...)  # serialized object\n",
    "    df.to_sql(...)  # to SQL database\n",
    "    df.to_excel(...)  # to Excel sheet\n",
    "    df.to_json(...)  # to JSON string\n",
    "    df.to_html(...)  # render as HTML table\n",
    "    df.to_feather(...)  # binary feather-format\n",
    "    df.to_latex(...)  # tabular environment table\n",
    "    df.to_stata(...)  # Stata binary data files\n",
    "    df.to_msgpack(...)\t# msgpack (serialize) object\n",
    "    df.to_gbq(...)  # to a Google BigQuery table.\n",
    "    df.to_string(...)  # console-friendly tabular output.\n",
    "    df.to_clipboard(...) # clipboard that can be pasted into Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
